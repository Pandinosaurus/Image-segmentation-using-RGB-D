name: "Res_101"
force_backward: true
layer { top: 'data' top: 'label' name: 'loaddata'       type: 'HDF5Data'  hdf5_data_param { source: 'train.txt' batch_size: 1 shuffle: true} }
#layer { top: 'data' top: 'label' name: 'loaddata'       type: 'HDF5Data'  hdf5_data_param { source: 'val.txt' batch_size: 1 } }

#layer {
#  name: "input"
#  type: "Input"
#  top: "data"
#  input_param { shape { dim: 1 dim: 4 dim: 1024 dim: 1024} }
#}


###################### resolution 1 #####################
layer {  bottom: "data"    top: "conv0a" name: "conv0a"  type: "Convolution"    convolution_param {    num_output: 64    pad: 1    kernel_size: 3  bias_term: false  stride: 1 weight_filler {  type: "msra" } bias_filler {type: "constant" value: 0}}}
layer {  bottom: "conv0a"  top: "conv0a" name: "bn_conv0a"  type: "BatchNorm"    param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {  bottom: "conv0a"  top: "conv0a" name: "scale_conv0a"  type: "Scale"    scale_param {    bias_term: true  }}
layer {  bottom: "conv0a"  top: "conv0a" name: "conv0a_relu"  type: "ReLU"  }#(64X768X768)

layer {  bottom: "conv0a"  top: "conv0b" name: "conv0b"  type: "Convolution"    convolution_param {num_output: 64    pad: 1    kernel_size: 3  bias_term: false  stride: 1  weight_filler {  type: "msra"  }  bias_filler {type: "constant" value: 0}}}
layer {  bottom: "conv0b"  top: "conv0b" name: "bn_conv0b"  type: "BatchNorm"    param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {  bottom: "conv0b"  top: "conv0b" name: "scale_conv0b"  type: "Scale"    scale_param {    bias_term: true  }}
layer {  bottom: "conv0b"  top: "conv0b" name: "conv0b_relu"  type: "ReLU"  }#(64X768X768)

layer {  bottom: "conv0b"  top: "conv0c" name: "conv0c"  type: "Convolution"    convolution_param {num_output: 64    pad: 1  kernel_size: 3  bias_term: false  stride: 1  weight_filler {   type: "msra" }  bias_filler { type: "constant" value: 0}}}
layer {  bottom: "conv0c"  top: "conv0c" name: "bn_conv0c"  type: "BatchNorm"    param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {  bottom: "conv0c"  top: "conv0c" name: "scale_conv0c"  type: "Scale"    scale_param {    bias_term: true  }}
layer {  bottom: "conv0c"  top: "conv0c" name: "conv0c_relu"  type: "ReLU"  }#(64X768X768)

################################################################################################## Transition Down ###########################################################################################################################

layer {  bottom: "conv0c"    top: "conv1a" name: "conv1a"  type: "Convolution"    convolution_param {num_output: 64    pad: 1    kernel_size: 3  bias_term: false  stride: 2 weight_filler {  type: "msra" } bias_filler {type: "constant" value: 0}}}
layer {  bottom: "conv1a"  top: "conv1a" name: "bn_conv1a"  type: "BatchNorm"    param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {  bottom: "conv1a"  top: "conv1a" name: "scale_conv1a"  type: "Scale"    scale_param {    bias_term: true  }}
layer {  bottom: "conv1a"  top: "conv1a" name: "conv1a_relu"  type: "ReLU"  }#(64X768X768)

layer {  bottom: "conv1a"  top: "conv1b" name: "conv1b"  type: "Convolution"    convolution_param {num_output: 64    pad: 1    kernel_size: 3  bias_term: false  stride: 1  weight_filler {  type: "msra"  }  bias_filler {type: "constant" value: 0}}}
layer {  bottom: "conv1b"  top: "conv1b" name: "bn_conv1b"  type: "BatchNorm"    param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {  bottom: "conv1b"  top: "conv1b" name: "scale_conv1b"  type: "Scale"    scale_param {    bias_term: true  }}
layer {  bottom: "conv1b"  top: "conv1b" name: "conv1b_relu"  type: "ReLU"  }#(64X768X768)

layer {  bottom: "conv1b"  top: "conv1c" name: "conv1c"  type: "Convolution"    convolution_param {num_output: 64    pad: 1  kernel_size: 3  bias_term: false  stride: 1  weight_filler {   type: "msra" }  bias_filler { type: "constant" value: 0}}}
layer {  bottom: "conv1c"  top: "conv1c" name: "bn_conv1c"  type: "BatchNorm"    param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {  bottom: "conv1c"  top: "conv1c" name: "scale_conv1c"  type: "Scale"    scale_param {    bias_term: true  }}
layer {  bottom: "conv1c"  top: "conv1c" name: "conv1c_relu"  type: "ReLU"  }#(64X768X768)

################################################################################################## Transition Down ###########################################################################################################################

layer {        bottom: "conv1c"        top: "pool1"        name: "pool1"        type: "Pooling"        pooling_param {                kernel_size: 3                stride: 2                pool: MAX        }}

############################################################################################### No Transition Down ###########################################################################################################################

layer {        bottom: "pool1"        top: "res2a_branch1"        name: "res2a_branch1"        type: "Convolution" convolution_param{                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res2a_branch1"        top: "res2a_branch1"        name: "bn2a_branch1"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2a_branch1"        top: "res2a_branch1"        name: "scale2a_branch1"        type: "Scale"        scale_param {                bias_term: true        }}

#################################################################################################### Res Block 1 #############################################################################################################################

layer {        bottom: "pool1"        top: "res2a_branch2a"        name: "res2a_branch2a"        type: "Convolution"               convolution_param {                num_output: 64                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res2a_branch2a"        top: "res2a_branch2a"        name: "bn2a_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2a_branch2a"        top: "res2a_branch2a"        name: "scale2a_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res2a_branch2a"        bottom: "res2a_branch2a"        name: "res2a_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res2a_branch2a"        top: "res2a_branch2b"        name: "res2a_branch2b"        type: "Convolution"               convolution_param {                num_output: 64                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                stride: 1                bias_term: false        }}
layer {        bottom: "res2a_branch2b"        top: "res2a_branch2b"        name: "bn2a_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2a_branch2b"        top: "res2a_branch2b"        name: "scale2a_branch2b"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res2a_branch2b"        bottom: "res2a_branch2b"        name: "res2a_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res2a_branch2b"        top: "res2a_branch2c"        name: "res2a_branch2c"        type: "Convolution"               convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res2a_branch2c"        top: "res2a_branch2c"        name: "bn2a_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2a_branch2c"        top: "res2a_branch2c"        name: "scale2a_branch2c"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        bottom: "res2a_branch1"        bottom: "res2a_branch2c"        top: "res2a"        name: "res2a"        type: "Eltwise"}
layer {        bottom: "res2a"        top: "res2a"        name: "res2a_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res2a"        top: "res2b_branch2a"        name: "res2b_branch2a"        type: "Convolution"              convolution_param {                num_output: 64                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res2b_branch2a"        top: "res2b_branch2a"        name: "bn2b_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2b_branch2a"        top: "res2b_branch2a"        name: "scale2b_branch2a"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res2b_branch2a"        bottom: "res2b_branch2a"        name: "res2b_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res2b_branch2a"        top: "res2b_branch2b"        name: "res2b_branch2b"        type: "Convolution"               convolution_param {                num_output: 64                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                stride: 1                bias_term: false        }}
layer {        bottom: "res2b_branch2b"        top: "res2b_branch2b"        name: "bn2b_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2b_branch2b"        top: "res2b_branch2b"        name: "scale2b_branch2b"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res2b_branch2b"        bottom: "res2b_branch2b"        name: "res2b_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res2b_branch2b"        top: "res2b_branch2c"        name: "res2b_branch2c"        type: "Convolution"               convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res2b_branch2c"        top: "res2b_branch2c"        name: "bn2b_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2b_branch2c"        top: "res2b_branch2c"        name: "scale2b_branch2c"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        bottom: "res2a"        bottom: "res2b_branch2c"        top: "res2b"        name: "res2b"        type: "Eltwise"}
layer {        bottom: "res2b"        top: "res2b"        name: "res2b_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res2b"        top: "res2c_branch2a"        name: "res2c_branch2a"        type: "Convolution"               convolution_param {                num_output: 64                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res2c_branch2a"        top: "res2c_branch2a"        name: "bn2c_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2c_branch2a"        top: "res2c_branch2a"        name: "scale2c_branch2a"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res2c_branch2a"        bottom: "res2c_branch2a"        name: "res2c_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res2c_branch2a"        top: "res2c_branch2b"        name: "res2c_branch2b"        type: "Convolution"               convolution_param {                num_output: 64                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                stride: 1                bias_term: false        }}
layer {        bottom: "res2c_branch2b"        top: "res2c_branch2b"        name: "bn2c_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2c_branch2b"        top: "res2c_branch2b"        name: "scale2c_branch2b"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res2c_branch2b"        bottom: "res2c_branch2b"        name: "res2c_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res2c_branch2b"        top: "res2c_branch2c"        name: "res2c_branch2c"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res2c_branch2c"        top: "res2c_branch2c"        name: "bn2c_branch2c"        type: "BatchNorm"       param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res2c_branch2c"        top: "res2c_branch2c"        name: "scale2c_branch2c"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        bottom: "res2b"        bottom: "res2c_branch2c"        top: "res2c"        name: "res2c"        type: "Eltwise"}
layer {        bottom: "res2c"        top: "res2c"        name: "res2c_relu"        type: "ReLU"}

################################################################################################### Transition Down  ##########################################################################################################################

layer {        bottom: "res2c"        top: "res3a_branch1"        name: "res3a_branch1"        type: "Convolution"            convolution_param{                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 2                bias_term: false        }}
layer {        bottom: "res3a_branch1"        top: "res3a_branch1"        name: "bn3a_branch1"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3a_branch1"        top: "res3a_branch1"        name: "scale3a_branch1"        type: "Scale"        scale_param {                bias_term: true        }        }

################################################################################################# Res Block 2 #################################################################################################################################

layer {        bottom: "res2c"        top: "res3a_branch2a"        name: "res3a_branch2a"        type: "Convolution"             convolution_param {                num_output: 128                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 2                bias_term: false        }}
layer {        bottom: "res3a_branch2a"        top: "res3a_branch2a"        name: "bn3a_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3a_branch2a"        top: "res3a_branch2a"        name: "scale3a_branch2a"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3a_branch2a"        bottom: "res3a_branch2a"        name: "res3a_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res3a_branch2a"        top: "res3a_branch2b"        name: "res3a_branch2b"        type: "Convolution"              convolution_param {                num_output: 128                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                stride: 1                bias_term: false        }}
layer {        bottom: "res3a_branch2b"        top: "res3a_branch2b"        name: "bn3a_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3a_branch2b"        top: "res3a_branch2b"        name: "scale3a_branch2b"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3a_branch2b"        bottom: "res3a_branch2b"        name: "res3a_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res3a_branch2b"        top: "res3a_branch2c"        name: "res3a_branch2c"        type: "Convolution"            convolution_param {                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res3a_branch2c"        top: "res3a_branch2c"        name: "bn3a_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3a_branch2c"        top: "res3a_branch2c"        name: "scale3a_branch2c"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        bottom: "res3a_branch1"        bottom: "res3a_branch2c"        top: "res3a"        name: "res3a"        type: "Eltwise"}
layer {        bottom: "res3a"        top: "res3a"        name: "res3a_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res3a"        top: "res3b1_branch2a"        name: "res3b1_branch2a"        type: "Convolution"             convolution_param {                num_output: 128                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res3b1_branch2a"        top: "res3b1_branch2a"        name: "bn3b1_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b1_branch2a"        top: "res3b1_branch2a"        name: "scale3b1_branch2a"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3b1_branch2a"        bottom: "res3b1_branch2a"        name: "res3b1_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res3b1_branch2a"        top: "res3b1_branch2b"        name: "res3b1_branch2b"        type: "Convolution"            convolution_param {                num_output: 128                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                stride: 1                bias_term: false        }}
layer {        bottom: "res3b1_branch2b"        top: "res3b1_branch2b"        name: "bn3b1_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b1_branch2b"        top: "res3b1_branch2b"        name: "scale3b1_branch2b"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3b1_branch2b"        bottom: "res3b1_branch2b"        name: "res3b1_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res3b1_branch2b"        top: "res3b1_branch2c"        name: "res3b1_branch2c"        type: "Convolution"             convolution_param {                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res3b1_branch2c"        top: "res3b1_branch2c"        name: "bn3b1_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b1_branch2c"        top: "res3b1_branch2c"        name: "scale3b1_branch2c"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        bottom: "res3a"        bottom: "res3b1_branch2c"        top: "res3b1"        name: "res3b1"        type: "Eltwise"}
layer {        bottom: "res3b1"        top: "res3b1"        name: "res3b1_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res3b1"        top: "res3b2_branch2a"        name: "res3b2_branch2a"        type: "Convolution"            convolution_param {                num_output: 128                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res3b2_branch2a"        top: "res3b2_branch2a"        name: "bn3b2_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b2_branch2a"        top: "res3b2_branch2a"        name: "scale3b2_branch2a"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3b2_branch2a"        bottom: "res3b2_branch2a"        name: "res3b2_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res3b2_branch2a"        top: "res3b2_branch2b"        name: "res3b2_branch2b"        type: "Convolution"           convolution_param {                num_output: 128                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                stride: 1                bias_term: false        }}
layer {        bottom: "res3b2_branch2b"        top: "res3b2_branch2b"        name: "bn3b2_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b2_branch2b"        top: "res3b2_branch2b"        name: "scale3b2_branch2b"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3b2_branch2b"        bottom: "res3b2_branch2b"        name: "res3b2_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res3b2_branch2b"        top: "res3b2_branch2c"        name: "res3b2_branch2c"        type: "Convolution"            convolution_param {                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res3b2_branch2c"        top: "res3b2_branch2c"        name: "bn3b2_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b2_branch2c"        top: "res3b2_branch2c"        name: "scale3b2_branch2c"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        bottom: "res3b1"        bottom: "res3b2_branch2c"        top: "res3b2"        name: "res3b2"        type: "Eltwise"}
layer {        bottom: "res3b2"        top: "res3b2"        name: "res3b2_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res3b2"        top: "res3b3_branch2a"        name: "res3b3_branch2a"        type: "Convolution"            convolution_param {                num_output: 128                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res3b3_branch2a"        top: "res3b3_branch2a"        name: "bn3b3_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b3_branch2a"        top: "res3b3_branch2a"        name: "scale3b3_branch2a"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3b3_branch2a"        bottom: "res3b3_branch2a"        name: "res3b3_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res3b3_branch2a"        top: "res3b3_branch2b"        name: "res3b3_branch2b"        type: "Convolution"            convolution_param {                num_output: 128                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                stride: 1                bias_term: false        }}
layer {        bottom: "res3b3_branch2b"        top: "res3b3_branch2b"        name: "bn3b3_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b3_branch2b"        top: "res3b3_branch2b"        name: "scale3b3_branch2b"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res3b3_branch2b"        bottom: "res3b3_branch2b"        name: "res3b3_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res3b3_branch2b"        top: "res3b3_branch2c"        name: "res3b3_branch2c"        type: "Convolution"            convolution_param {                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res3b3_branch2c"        top: "res3b3_branch2c"        name: "bn3b3_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res3b3_branch2c"        top: "res3b3_branch2c"        name: "scale3b3_branch2c"        type: "Scale"        scale_param {                bias_term: true        }       }
layer {        bottom: "res3b2"        bottom: "res3b3_branch2c"        top: "res3b3"        name: "res3b3"        type: "Eltwise"}
layer {        bottom: "res3b3"        top: "res3b3"        name: "res3b3_relu"        type: "ReLU"}

################################################################################################### Transition Down  ##########################################################################################################################

layer {        bottom: "res3b3"        top: "res4a_branch1"        name: "res4a_branch1"        type: "Convolution"          convolution_param{                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 2                bias_term: false        }}
layer {        bottom: "res4a_branch1"        top: "res4a_branch1"        name: "bn4a_branch1"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4a_branch1"        top: "res4a_branch1"        name: "scale4a_branch1"        type: "Scale"        scale_param {                bias_term: true        }        }

################################################################################################# Res Block 3 #################################################################################################################################

layer {        bottom: "res3b3"        top: "res4a_branch2a"        name: "res4a_branch2a"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 2                bias_term: false        }}
layer {        bottom: "res4a_branch2a"        top: "res4a_branch2a"        name: "bn4a_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4a_branch2a"        top: "res4a_branch2a"        name: "scale4a_branch2a"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        top: "res4a_branch2a"        bottom: "res4a_branch2a"        name: "res4a_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4a_branch2a"        top: "res4a_branch2b"        name: "res4a_branch2b"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                         stride: 1                bias_term: false        }}
layer {        bottom: "res4a_branch2b"        top: "res4a_branch2b"        name: "bn4a_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4a_branch2b"        top: "res4a_branch2b"        name: "scale4a_branch2b"        type: "Scale"        scale_param {                bias_term: true        }       }
layer {        top: "res4a_branch2b"        bottom: "res4a_branch2b"        name: "res4a_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4a_branch2b"        top: "res4a_branch2c"        name: "res4a_branch2c"        type: "Convolution"             convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4a_branch2c"        top: "res4a_branch2c"        name: "bn4a_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4a_branch2c"        top: "res4a_branch2c"        name: "scale4a_branch2c"        type: "Scale"        scale_param {                bias_term: true        }        }
layer {        bottom: "res4a_branch1"        bottom: "res4a_branch2c"        top: "res4a"        name: "res4a"        type: "Eltwise"}
layer {        bottom: "res4a"        top: "res4a"        name: "res4a_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4a"        top: "res4b1_branch2a"        name: "res4b1_branch2a"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b1_branch2a"        top: "res4b1_branch2a"        name: "bn4b1_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b1_branch2a"        top: "res4b1_branch2a"        name: "scale4b1_branch2a"        type: "Scale"        scale_param {                bias_term: true        }       }
layer {        top: "res4b1_branch2a"        bottom: "res4b1_branch2a"        name: "res4b1_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b1_branch2a"        top: "res4b1_branch2b"        name: "res4b1_branch2b"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b1_branch2b"        top: "res4b1_branch2b"        name: "bn4b1_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b1_branch2b"        top: "res4b1_branch2b"        name: "scale4b1_branch2b"        type: "Scale"        scale_param {                bias_term: true        }     }
layer {        top: "res4b1_branch2b"        bottom: "res4b1_branch2b"        name: "res4b1_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b1_branch2b"        top: "res4b1_branch2c"        name: "res4b1_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b1_branch2c"        top: "res4b1_branch2c"        name: "bn4b1_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b1_branch2c"        top: "res4b1_branch2c"        name: "scale4b1_branch2c"        type: "Scale"        scale_param {                bias_term: true        }      }
layer {        bottom: "res4a"        bottom: "res4b1_branch2c"        top: "res4b1"        name: "res4b1"        type: "Eltwise"}
layer {        bottom: "res4b1"        top: "res4b1"        name: "res4b1_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b1"        top: "res4b2_branch2a"        name: "res4b2_branch2a"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b2_branch2a"        top: "res4b2_branch2a"        name: "bn4b2_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b2_branch2a"        top: "res4b2_branch2a"        name: "scale4b2_branch2a"        type: "Scale"        scale_param {                bias_term: true        }      }
layer {        top: "res4b2_branch2a"        bottom: "res4b2_branch2a"        name: "res4b2_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b2_branch2a"        top: "res4b2_branch2b"        name: "res4b2_branch2b"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b2_branch2b"        top: "res4b2_branch2b"        name: "bn4b2_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b2_branch2b"        top: "res4b2_branch2b"        name: "scale4b2_branch2b"        type: "Scale"        scale_param {                bias_term: true        }    }
layer {        top: "res4b2_branch2b"        bottom: "res4b2_branch2b"        name: "res4b2_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b2_branch2b"        top: "res4b2_branch2c"        name: "res4b2_branch2c"        type: "Convolution"          convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b2_branch2c"        top: "res4b2_branch2c"        name: "bn4b2_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b2_branch2c"        top: "res4b2_branch2c"        name: "scale4b2_branch2c"        type: "Scale"        scale_param {                bias_term: true        }     }
layer {        bottom: "res4b1"        bottom: "res4b2_branch2c"        top: "res4b2"        name: "res4b2"        type: "Eltwise"}
layer {        bottom: "res4b2"        top: "res4b2"        name: "res4b2_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b2"        top: "res4b3_branch2a"        name: "res4b3_branch2a"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b3_branch2a"        top: "res4b3_branch2a"        name: "bn4b3_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b3_branch2a"        top: "res4b3_branch2a"        name: "scale4b3_branch2a"        type: "Scale"        scale_param {                bias_term: true        }     }
layer {        top: "res4b3_branch2a"        bottom: "res4b3_branch2a"        name: "res4b3_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b3_branch2a"        top: "res4b3_branch2b"        name: "res4b3_branch2b"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                                stride: 1                bias_term: false        }}
layer {        bottom: "res4b3_branch2b"        top: "res4b3_branch2b"        name: "bn4b3_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b3_branch2b"        top: "res4b3_branch2b"        name: "scale4b3_branch2b"        type: "Scale"        scale_param {                bias_term: true        }    }
layer {        top: "res4b3_branch2b"        bottom: "res4b3_branch2b"        name: "res4b3_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b3_branch2b"        top: "res4b3_branch2c"        name: "res4b3_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b3_branch2c"        top: "res4b3_branch2c"        name: "bn4b3_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b3_branch2c"        top: "res4b3_branch2c"        name: "scale4b3_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b2"        bottom: "res4b3_branch2c"        top: "res4b3"        name: "res4b3"        type: "Eltwise"}
layer {        bottom: "res4b3"        top: "res4b3"        name: "res4b3_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b3"        top: "res4b4_branch2a"        name: "res4b4_branch2a"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b4_branch2a"        top: "res4b4_branch2a"        name: "bn4b4_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b4_branch2a"        top: "res4b4_branch2a"        name: "scale4b4_branch2a"        type: "Scale"        scale_param {                bias_term: true        }    }
layer {        top: "res4b4_branch2a"        bottom: "res4b4_branch2a"        name: "res4b4_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b4_branch2a"        top: "res4b4_branch2b"        name: "res4b4_branch2b"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                                stride: 1                bias_term: false        }}
layer {        bottom: "res4b4_branch2b"        top: "res4b4_branch2b"        name: "bn4b4_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b4_branch2b"        top: "res4b4_branch2b"        name: "scale4b4_branch2b"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b4_branch2b"        bottom: "res4b4_branch2b"        name: "res4b4_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b4_branch2b"        top: "res4b4_branch2c"        name: "res4b4_branch2c"        type: "Convolution"           convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b4_branch2c"        top: "res4b4_branch2c"        name: "bn4b4_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b4_branch2c"        top: "res4b4_branch2c"        name: "scale4b4_branch2c"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        bottom: "res4b3"        bottom: "res4b4_branch2c"        top: "res4b4"        name: "res4b4"        type: "Eltwise"}
layer {        bottom: "res4b4"        top: "res4b4"        name: "res4b4_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b4"        top: "res4b5_branch2a"        name: "res4b5_branch2a"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b5_branch2a"        top: "res4b5_branch2a"        name: "bn4b5_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b5_branch2a"        top: "res4b5_branch2a"        name: "scale4b5_branch2a"        type: "Scale"        scale_param {                bias_term: true        }     }
layer {        top: "res4b5_branch2a"        bottom: "res4b5_branch2a"        name: "res4b5_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b5_branch2a"        top: "res4b5_branch2b"        name: "res4b5_branch2b"        type: "Convolution"         convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                                stride: 1                bias_term: false        }}
layer {        bottom: "res4b5_branch2b"        top: "res4b5_branch2b"        name: "bn4b5_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b5_branch2b"        top: "res4b5_branch2b"        name: "scale4b5_branch2b"        type: "Scale"        scale_param {                bias_term: true        }     }
layer {        top: "res4b5_branch2b"        bottom: "res4b5_branch2b"        name: "res4b5_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b5_branch2b"        top: "res4b5_branch2c"        name: "res4b5_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b5_branch2c"        top: "res4b5_branch2c"        name: "bn4b5_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b5_branch2c"        top: "res4b5_branch2c"        name: "scale4b5_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b4"        bottom: "res4b5_branch2c"        top: "res4b5"        name: "res4b5"        type: "Eltwise"}
layer {        bottom: "res4b5"        top: "res4b5"        name: "res4b5_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b5"        top: "res4b6_branch2a"        name: "res4b6_branch2a"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b6_branch2a"        top: "res4b6_branch2a"        name: "bn4b6_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b6_branch2a"        top: "res4b6_branch2a"        name: "scale4b6_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b6_branch2a"        bottom: "res4b6_branch2a"        name: "res4b6_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b6_branch2a"        top: "res4b6_branch2b"        name: "res4b6_branch2b"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b6_branch2b"        top: "res4b6_branch2b"        name: "bn4b6_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b6_branch2b"        top: "res4b6_branch2b"        name: "scale4b6_branch2b"        type: "Scale"        scale_param {                bias_term: true        }    }
layer {        top: "res4b6_branch2b"        bottom: "res4b6_branch2b"        name: "res4b6_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b6_branch2b"        top: "res4b6_branch2c"        name: "res4b6_branch2c"        type: "Convolution"         convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {       bottom: "res4b6_branch2c"        top: "res4b6_branch2c"        name: "bn4b6_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b6_branch2c"        top: "res4b6_branch2c"        name: "scale4b6_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b5"        bottom: "res4b6_branch2c"        top: "res4b6"        name: "res4b6"        type: "Eltwise"}
layer {        bottom: "res4b6"        top: "res4b6"        name: "res4b6_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b6"        top: "res4b7_branch2a"        name: "res4b7_branch2a"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b7_branch2a"        top: "res4b7_branch2a"        name: "bn4b7_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b7_branch2a"        top: "res4b7_branch2a"        name: "scale4b7_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b7_branch2a"        bottom: "res4b7_branch2a"        name: "res4b7_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b7_branch2a"        top: "res4b7_branch2b"        name: "res4b7_branch2b"        type: "Convolution"              convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b7_branch2b"        top: "res4b7_branch2b"        name: "bn4b7_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b7_branch2b"        top: "res4b7_branch2b"        name: "scale4b7_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b7_branch2b"        bottom: "res4b7_branch2b"        name: "res4b7_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b7_branch2b"        top: "res4b7_branch2c"        name: "res4b7_branch2c"        type: "Convolution"             convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b7_branch2c"        top: "res4b7_branch2c"        name: "bn4b7_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b7_branch2c"        top: "res4b7_branch2c"        name: "scale4b7_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b6"        bottom: "res4b7_branch2c"        top: "res4b7"        name: "res4b7"        type: "Eltwise"}
layer {        bottom: "res4b7"        top: "res4b7"        name: "res4b7_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b7"        top: "res4b8_branch2a"        name: "res4b8_branch2a"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b8_branch2a"        top: "res4b8_branch2a"        name: "bn4b8_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b8_branch2a"        top: "res4b8_branch2a"        name: "scale4b8_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b8_branch2a"        bottom: "res4b8_branch2a"        name: "res4b8_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b8_branch2a"        top: "res4b8_branch2b"        name: "res4b8_branch2b"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b8_branch2b"        top: "res4b8_branch2b"        name: "bn4b8_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b8_branch2b"        top: "res4b8_branch2b"        name: "scale4b8_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b8_branch2b"        bottom: "res4b8_branch2b"        name: "res4b8_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b8_branch2b"        top: "res4b8_branch2c"        name: "res4b8_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b8_branch2c"        top: "res4b8_branch2c"        name: "bn4b8_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b8_branch2c"        top: "res4b8_branch2c"        name: "scale4b8_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b7"        bottom: "res4b8_branch2c"        top: "res4b8"        name: "res4b8"        type: "Eltwise"}
layer {        bottom: "res4b8"        top: "res4b8"        name: "res4b8_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b8"        top: "res4b9_branch2a"        name: "res4b9_branch2a"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b9_branch2a"        top: "res4b9_branch2a"        name: "bn4b9_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b9_branch2a"        top: "res4b9_branch2a"        name: "scale4b9_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b9_branch2a"        bottom: "res4b9_branch2a"        name: "res4b9_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b9_branch2a"        top: "res4b9_branch2b"        name: "res4b9_branch2b"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                              stride: 1                bias_term: false        }}
layer {        bottom: "res4b9_branch2b"        top: "res4b9_branch2b"        name: "bn4b9_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b9_branch2b"        top: "res4b9_branch2b"        name: "scale4b9_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b9_branch2b"        bottom: "res4b9_branch2b"        name: "res4b9_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b9_branch2b"        top: "res4b9_branch2c"        name: "res4b9_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b9_branch2c"        top: "res4b9_branch2c"        name: "bn4b9_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b9_branch2c"        top: "res4b9_branch2c"        name: "scale4b9_branch2c"        type: "Scale"        scale_param {                bias_term: true        }     }
layer {        bottom: "res4b8"        bottom: "res4b9_branch2c"        top: "res4b9"        name: "res4b9"        type: "Eltwise"}
layer {        bottom: "res4b9"        top: "res4b9"        name: "res4b9_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b9"        top: "res4b10_branch2a"        name: "res4b10_branch2a"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b10_branch2a"        top: "res4b10_branch2a"        name: "bn4b10_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b10_branch2a"        top: "res4b10_branch2a"        name: "scale4b10_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b10_branch2a"        bottom: "res4b10_branch2a"        name: "res4b10_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b10_branch2a"        top: "res4b10_branch2b"        name: "res4b10_branch2b"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b10_branch2b"        top: "res4b10_branch2b"        name: "bn4b10_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b10_branch2b"        top: "res4b10_branch2b"        name: "scale4b10_branch2b"        type: "Scale"        scale_param {                bias_term: true        }    }
layer {        top: "res4b10_branch2b"        bottom: "res4b10_branch2b"        name: "res4b10_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b10_branch2b"        top: "res4b10_branch2c"        name: "res4b10_branch2c"        type: "Convolution"           convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b10_branch2c"        top: "res4b10_branch2c"        name: "bn4b10_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b10_branch2c"        top: "res4b10_branch2c"        name: "scale4b10_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b9"        bottom: "res4b10_branch2c"        top: "res4b10"        name: "res4b10"        type: "Eltwise"}
layer {        bottom: "res4b10"        top: "res4b10"        name: "res4b10_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b10"        top: "res4b11_branch2a"        name: "res4b11_branch2a"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b11_branch2a"        top: "res4b11_branch2a"        name: "bn4b11_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b11_branch2a"        top: "res4b11_branch2a"        name: "scale4b11_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b11_branch2a"        bottom: "res4b11_branch2a"        name: "res4b11_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b11_branch2a"        top: "res4b11_branch2b"        name: "res4b11_branch2b"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b11_branch2b"        top: "res4b11_branch2b"        name: "bn4b11_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b11_branch2b"        top: "res4b11_branch2b"        name: "scale4b11_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b11_branch2b"        bottom: "res4b11_branch2b"        name: "res4b11_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b11_branch2b"        top: "res4b11_branch2c"        name: "res4b11_branch2c"        type: "Convolution"          convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b11_branch2c"        top: "res4b11_branch2c"        name: "bn4b11_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b11_branch2c"        top: "res4b11_branch2c"        name: "scale4b11_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b10"        bottom: "res4b11_branch2c"        top: "res4b11"        name: "res4b11"        type: "Eltwise"}
layer {        bottom: "res4b11"        top: "res4b11"        name: "res4b11_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b11"        top: "res4b12_branch2a"        name: "res4b12_branch2a"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b12_branch2a"        top: "res4b12_branch2a"        name: "bn4b12_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b12_branch2a"        top: "res4b12_branch2a"        name: "scale4b12_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b12_branch2a"        bottom: "res4b12_branch2a"        name: "res4b12_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b12_branch2a"        top: "res4b12_branch2b"        name: "res4b12_branch2b"        type: "Convolution"         convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                         stride: 1                bias_term: false        }}
layer {        bottom: "res4b12_branch2b"        top: "res4b12_branch2b"        name: "bn4b12_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b12_branch2b"        top: "res4b12_branch2b"        name: "scale4b12_branch2b"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b12_branch2b"        bottom: "res4b12_branch2b"        name: "res4b12_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b12_branch2b"        top: "res4b12_branch2c"        name: "res4b12_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b12_branch2c"        top: "res4b12_branch2c"        name: "bn4b12_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b12_branch2c"        top: "res4b12_branch2c"        name: "scale4b12_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b11"        bottom: "res4b12_branch2c"        top: "res4b12"        name: "res4b12"        type: "Eltwise"}
layer {        bottom: "res4b12"        top: "res4b12"        name: "res4b12_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b12"        top: "res4b13_branch2a"        name: "res4b13_branch2a"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b13_branch2a"        top: "res4b13_branch2a"        name: "bn4b13_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b13_branch2a"        top: "res4b13_branch2a"        name: "scale4b13_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b13_branch2a"        bottom: "res4b13_branch2a"        name: "res4b13_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b13_branch2a"        top: "res4b13_branch2b"        name: "res4b13_branch2b"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                             stride: 1                bias_term: false        }}
layer {        bottom: "res4b13_branch2b"        top: "res4b13_branch2b"        name: "bn4b13_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b13_branch2b"        top: "res4b13_branch2b"        name: "scale4b13_branch2b"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        top: "res4b13_branch2b"        bottom: "res4b13_branch2b"        name: "res4b13_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b13_branch2b"        top: "res4b13_branch2c"        name: "res4b13_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b13_branch2c"        top: "res4b13_branch2c"        name: "bn4b13_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b13_branch2c"        top: "res4b13_branch2c"        name: "scale4b13_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b12"        bottom: "res4b13_branch2c"        top: "res4b13"        name: "res4b13"        type: "Eltwise"}
layer {        bottom: "res4b13"        top: "res4b13"        name: "res4b13_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b13"        top: "res4b14_branch2a"        name: "res4b14_branch2a"        type: "Convolution"        convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b14_branch2a"        top: "res4b14_branch2a"        name: "bn4b14_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b14_branch2a"        top: "res4b14_branch2a"        name: "scale4b14_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b14_branch2a"        bottom: "res4b14_branch2a"        name: "res4b14_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b14_branch2a"        top: "res4b14_branch2b"        name: "res4b14_branch2b"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                              stride: 1                bias_term: false        }}
layer {        bottom: "res4b14_branch2b"        top: "res4b14_branch2b"        name: "bn4b14_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b14_branch2b"        top: "res4b14_branch2b"        name: "scale4b14_branch2b"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b14_branch2b"        bottom: "res4b14_branch2b"        name: "res4b14_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b14_branch2b"        top: "res4b14_branch2c"        name: "res4b14_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b14_branch2c"        top: "res4b14_branch2c"        name: "bn4b14_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b14_branch2c"        top: "res4b14_branch2c"        name: "scale4b14_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b13"        bottom: "res4b14_branch2c"        top: "res4b14"        name: "res4b14"        type: "Eltwise"}
layer {        bottom: "res4b14"        top: "res4b14"        name: "res4b14_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################


layer {        bottom: "res4b14"        top: "res4b15_branch2a"        name: "res4b15_branch2a"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b15_branch2a"        top: "res4b15_branch2a"        name: "bn4b15_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b15_branch2a"        top: "res4b15_branch2a"        name: "scale4b15_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b15_branch2a"        bottom: "res4b15_branch2a"        name: "res4b15_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b15_branch2a"        top: "res4b15_branch2b"        name: "res4b15_branch2b"        type: "Convolution"              convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                            stride: 1                bias_term: false        }}
layer {        bottom: "res4b15_branch2b"        top: "res4b15_branch2b"        name: "bn4b15_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b15_branch2b"        top: "res4b15_branch2b"        name: "scale4b15_branch2b"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        top: "res4b15_branch2b"        bottom: "res4b15_branch2b"        name: "res4b15_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b15_branch2b"        top: "res4b15_branch2c"        name: "res4b15_branch2c"        type: "Convolution"             convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b15_branch2c"        top: "res4b15_branch2c"        name: "bn4b15_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b15_branch2c"        top: "res4b15_branch2c"        name: "scale4b15_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b14"        bottom: "res4b15_branch2c"        top: "res4b15"        name: "res4b15"        type: "Eltwise"}
layer {        bottom: "res4b15"        top: "res4b15"        name: "res4b15_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b15"        top: "res4b16_branch2a"        name: "res4b16_branch2a"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b16_branch2a"        top: "res4b16_branch2a"        name: "bn4b16_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b16_branch2a"        top: "res4b16_branch2a"        name: "scale4b16_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b16_branch2a"        bottom: "res4b16_branch2a"        name: "res4b16_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b16_branch2a"        top: "res4b16_branch2b"        name: "res4b16_branch2b"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                              stride: 1                bias_term: false        }}
layer {        bottom: "res4b16_branch2b"        top: "res4b16_branch2b"        name: "bn4b16_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b16_branch2b"        top: "res4b16_branch2b"        name: "scale4b16_branch2b"        type: "Scale"        scale_param {                bias_term: true        }}
layer {        top: "res4b16_branch2b"        bottom: "res4b16_branch2b"        name: "res4b16_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b16_branch2b"        top: "res4b16_branch2c"        name: "res4b16_branch2c"        type: "Convolution"           convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b16_branch2c"        top: "res4b16_branch2c"        name: "bn4b16_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b16_branch2c"        top: "res4b16_branch2c"        name: "scale4b16_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b15"        bottom: "res4b16_branch2c"        top: "res4b16"        name: "res4b16"        type: "Eltwise"}
layer {        bottom: "res4b16"        top: "res4b16"        name: "res4b16_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b16"        top: "res4b17_branch2a"        name: "res4b17_branch2a"        type: "Convolution"              convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b17_branch2a"        top: "res4b17_branch2a"        name: "bn4b17_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b17_branch2a"        top: "res4b17_branch2a"        name: "scale4b17_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b17_branch2a"        bottom: "res4b17_branch2a"        name: "res4b17_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b17_branch2a"        top: "res4b17_branch2b"        name: "res4b17_branch2b"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                             stride: 1                bias_term: false        }}
layer {        bottom: "res4b17_branch2b"        top: "res4b17_branch2b"        name: "bn4b17_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b17_branch2b"        top: "res4b17_branch2b"        name: "scale4b17_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b17_branch2b"        bottom: "res4b17_branch2b"        name: "res4b17_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b17_branch2b"        top: "res4b17_branch2c"        name: "res4b17_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b17_branch2c"        top: "res4b17_branch2c"        name: "bn4b17_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b17_branch2c"        top: "res4b17_branch2c"        name: "scale4b17_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b16"        bottom: "res4b17_branch2c"        top: "res4b17"        name: "res4b17"        type: "Eltwise"}
layer {        bottom: "res4b17"        top: "res4b17"        name: "res4b17_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b17"        top: "res4b18_branch2a"        name: "res4b18_branch2a"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b18_branch2a"        top: "res4b18_branch2a"        name: "bn4b18_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b18_branch2a"        top: "res4b18_branch2a"        name: "scale4b18_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b18_branch2a"        bottom: "res4b18_branch2a"        name: "res4b18_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b18_branch2a"        top: "res4b18_branch2b"        name: "res4b18_branch2b"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                              stride: 1                bias_term: false        }}
layer {        bottom: "res4b18_branch2b"        top: "res4b18_branch2b"        name: "bn4b18_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b18_branch2b"        top: "res4b18_branch2b"        name: "scale4b18_branch2b"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b18_branch2b"        bottom: "res4b18_branch2b"        name: "res4b18_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b18_branch2b"        top: "res4b18_branch2c"        name: "res4b18_branch2c"        type: "Convolution"          convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b18_branch2c"        top: "res4b18_branch2c"        name: "bn4b18_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b18_branch2c"        top: "res4b18_branch2c"        name: "scale4b18_branch2c"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        bottom: "res4b17"        bottom: "res4b18_branch2c"        top: "res4b18"        name: "res4b18"        type: "Eltwise"}
layer {        bottom: "res4b18"        top: "res4b18"        name: "res4b18_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b18"        top: "res4b19_branch2a"        name: "res4b19_branch2a"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b19_branch2a"        top: "res4b19_branch2a"        name: "bn4b19_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b19_branch2a"        top: "res4b19_branch2a"        name: "scale4b19_branch2a"        type: "Scale"        scale_param {                bias_term: true        }}
layer {        top: "res4b19_branch2a"        bottom: "res4b19_branch2a"        name: "res4b19_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b19_branch2a"        top: "res4b19_branch2b"        name: "res4b19_branch2b"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                            stride: 1                bias_term: false        }}
layer {        bottom: "res4b19_branch2b"        top: "res4b19_branch2b"        name: "bn4b19_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b19_branch2b"        top: "res4b19_branch2b"        name: "scale4b19_branch2b"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b19_branch2b"        bottom: "res4b19_branch2b"        name: "res4b19_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b19_branch2b"        top: "res4b19_branch2c"        name: "res4b19_branch2c"        type: "Convolution"              convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b19_branch2c"        top: "res4b19_branch2c"        name: "bn4b19_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b19_branch2c"        top: "res4b19_branch2c"        name: "scale4b19_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b18"        bottom: "res4b19_branch2c"        top: "res4b19"        name: "res4b19"        type: "Eltwise"}
layer {        bottom: "res4b19"        top: "res4b19"        name: "res4b19_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b19"        top: "res4b20_branch2a"        name: "res4b20_branch2a"        type: "Convolution"          convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b20_branch2a"        top: "res4b20_branch2a"        name: "bn4b20_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b20_branch2a"        top: "res4b20_branch2a"        name: "scale4b20_branch2a"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        top: "res4b20_branch2a"        bottom: "res4b20_branch2a"        name: "res4b20_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b20_branch2a"        top: "res4b20_branch2b"        name: "res4b20_branch2b"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                             stride: 1                bias_term: false        }}
layer {        bottom: "res4b20_branch2b"        top: "res4b20_branch2b"        name: "bn4b20_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b20_branch2b"        top: "res4b20_branch2b"        name: "scale4b20_branch2b"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        top: "res4b20_branch2b"        bottom: "res4b20_branch2b"        name: "res4b20_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b20_branch2b"        top: "res4b20_branch2c"        name: "res4b20_branch2c"        type: "Convolution"              convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b20_branch2c"        top: "res4b20_branch2c"        name: "bn4b20_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b20_branch2c"        top: "res4b20_branch2c"        name: "scale4b20_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b19"        bottom: "res4b20_branch2c"        top: "res4b20"        name: "res4b20"        type: "Eltwise"}
layer {        bottom: "res4b20"        top: "res4b20"        name: "res4b20_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b20"        top: "res4b21_branch2a"        name: "res4b21_branch2a"        type: "Convolution"           convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {       bottom: "res4b21_branch2a"        top: "res4b21_branch2a"        name: "bn4b21_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b21_branch2a"        top: "res4b21_branch2a"        name: "scale4b21_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res4b21_branch2a"        bottom: "res4b21_branch2a"        name: "res4b21_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b21_branch2a"        top: "res4b21_branch2b"        name: "res4b21_branch2b"        type: "Convolution"            convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                               stride: 1                bias_term: false        }}
layer {        bottom: "res4b21_branch2b"        top: "res4b21_branch2b"        name: "bn4b21_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b21_branch2b"        top: "res4b21_branch2b"        name: "scale4b21_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b21_branch2b"        bottom: "res4b21_branch2b"        name: "res4b21_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b21_branch2b"        top: "res4b21_branch2c"        name: "res4b21_branch2c"        type: "Convolution"            convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b21_branch2c"        top: "res4b21_branch2c"        name: "bn4b21_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b21_branch2c"        top: "res4b21_branch2c"        name: "scale4b21_branch2c"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        bottom: "res4b20"        bottom: "res4b21_branch2c"        top: "res4b21"        name: "res4b21"        type: "Eltwise"}
layer {        bottom: "res4b21"        top: "res4b21"        name: "res4b21_relu"        type: "ReLU"}

############################################################################################################################################################################################################################################

layer {        bottom: "res4b21"        top: "res4b22_branch2a"        name: "res4b22_branch2a"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b22_branch2a"        top: "res4b22_branch2a"        name: "bn4b22_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b22_branch2a"        top: "res4b22_branch2a"        name: "scale4b22_branch2a"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res4b22_branch2a"        bottom: "res4b22_branch2a"        name: "res4b22_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res4b22_branch2a"        top: "res4b22_branch2b"        name: "res4b22_branch2b"        type: "Convolution"             convolution_param {                num_output: 256                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                              stride: 1                bias_term: false        }}
layer {        bottom: "res4b22_branch2b"        top: "res4b22_branch2b"        name: "bn4b22_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b22_branch2b"        top: "res4b22_branch2b"        name: "scale4b22_branch2b"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        top: "res4b22_branch2b"        bottom: "res4b22_branch2b"        name: "res4b22_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res4b22_branch2b"        top: "res4b22_branch2c"        name: "res4b22_branch2c"        type: "Convolution"           convolution_param {                num_output: 1024                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res4b22_branch2c"        top: "res4b22_branch2c"        name: "bn4b22_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res4b22_branch2c"        top: "res4b22_branch2c"        name: "scale4b22_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res4b21"        bottom: "res4b22_branch2c"        top: "res4b22"        name: "res4b22"        type: "Eltwise"}
layer {        bottom: "res4b22"        top: "res4b22"        name: "res4b22_relu"        type: "ReLU"}

#################################################################################################### Transition Down ###########################################################################################################################

layer {        bottom: "res4b22"        top: "res5a_branch1"        name: "res5a_branch1"        type: "Convolution"             convolution_param {                num_output: 2048                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 2                bias_term: false        }}
layer {        bottom: "res5a_branch1"        top: "res5a_branch1"        name: "bn5a_branch1"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5a_branch1"        top: "res5a_branch1"        name: "scale5a_branch1"        type: "Scale"        scale_param {                bias_term: true        }  }

#################################################################################################### Res Block 4 ################################################################################################################################

layer {        bottom: "res4b22"        top: "res5a_branch2a"        name: "res5a_branch2a"        type: "Convolution"     convolution_param {                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 2                bias_term: false        }}
layer {        bottom: "res5a_branch2a"        top: "res5a_branch2a"        name: "bn5a_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5a_branch2a"        top: "res5a_branch2a"        name: "scale5a_branch2a"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        top: "res5a_branch2a"        bottom: "res5a_branch2a"        name: "res5a_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res5a_branch2a"        top: "res5a_branch2b"        name: "res5a_branch2b"        type: "Convolution"              convolution_param {                num_output: 512                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                             stride: 1                bias_term: false        }}
layer {        bottom: "res5a_branch2b"        top: "res5a_branch2b"        name: "bn5a_branch2b"        type: "BatchNorm"       param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5a_branch2b"        top: "res5a_branch2b"        name: "scale5a_branch2b"        type: "Scale"        scale_param {                bias_term: true        }     }
layer {        top: "res5a_branch2b"        bottom: "res5a_branch2b"        name: "res5a_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res5a_branch2b"        top: "res5a_branch2c"        name: "res5a_branch2c"        type: "Convolution"             convolution_param {                num_output: 2048                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res5a_branch2c"        top: "res5a_branch2c"        name: "bn5a_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5a_branch2c"        top: "res5a_branch2c"        name: "scale5a_branch2c"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        bottom: "res5a_branch1"        bottom: "res5a_branch2c"        top: "res5a"        name: "res5a"        type: "Eltwise"}
layer {        bottom: "res5a"        top: "res5a"        name: "res5a_relu"        type: "ReLU"}

###############################################################################################################################################################################################################################################

layer {        bottom: "res5a"        top: "res5b_branch2a"        name: "res5b_branch2a"        type: "Convolution"             convolution_param {                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res5b_branch2a"        top: "res5b_branch2a"        name: "bn5b_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5b_branch2a"        top: "res5b_branch2a"        name: "scale5b_branch2a"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        top: "res5b_branch2a"        bottom: "res5b_branch2a"        name: "res5b_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res5b_branch2a"        top: "res5b_branch2b"        name: "res5b_branch2b"        type: "Convolution"            convolution_param {                num_output: 512                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                           stride: 1                bias_term: false        }}
layer {        bottom: "res5b_branch2b"        top: "res5b_branch2b"        name: "bn5b_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5b_branch2b"        top: "res5b_branch2b"        name: "scale5b_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res5b_branch2b"        bottom: "res5b_branch2b"        name: "res5b_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res5b_branch2b"        top: "res5b_branch2c"        name: "res5b_branch2c"        type: "Convolution"              convolution_param {                num_output: 2048                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res5b_branch2c"        top: "res5b_branch2c"        name: "bn5b_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5b_branch2c"        top: "res5b_branch2c"        name: "scale5b_branch2c"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        bottom: "res5a"        bottom: "res5b_branch2c"        top: "res5b"        name: "res5b"        type: "Eltwise"}
layer {        bottom: "res5b"        top: "res5b"        name: "res5b_relu"        type: "ReLU"}

###############################################################################################################################################################################################################################################

layer {        bottom: "res5b"        top: "res5c_branch2a"        name: "res5c_branch2a"        type: "Convolution"          convolution_param {                num_output: 512                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res5c_branch2a"        top: "res5c_branch2a"        name: "bn5c_branch2a"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5c_branch2a"        top: "res5c_branch2a"        name: "scale5c_branch2a"        type: "Scale"        scale_param {                bias_term: true        }  }
layer {        top: "res5c_branch2a"        bottom: "res5c_branch2a"        name: "res5c_branch2a_relu"        type: "ReLU"}

layer {        bottom: "res5c_branch2a"        top: "res5c_branch2b"        name: "res5c_branch2b"        type: "Convolution"             convolution_param {                num_output: 512                kernel_size: 3                weight_filler {  type: "msra" } pad: 1                              stride: 1                bias_term: false        }}
layer {        bottom: "res5c_branch2b"        top: "res5c_branch2b"        name: "bn5c_branch2b"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5c_branch2b"        top: "res5c_branch2b"        name: "scale5c_branch2b"        type: "Scale"        scale_param {                bias_term: true        }   }
layer {        top: "res5c_branch2b"        bottom: "res5c_branch2b"        name: "res5c_branch2b_relu"        type: "ReLU"}

layer {        bottom: "res5c_branch2b"        top: "res5c_branch2c"        name: "res5c_branch2c"        type: "Convolution"             convolution_param {                num_output: 2048                kernel_size: 1                weight_filler {  type: "msra" } pad: 0                stride: 1                bias_term: false        }}
layer {        bottom: "res5c_branch2c"        top: "res5c_branch2c"        name: "bn5c_branch2c"        type: "BatchNorm"        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer {        bottom: "res5c_branch2c"        top: "res5c_branch2c"        name: "scale5c_branch2c"        type: "Scale"        scale_param {                bias_term: true        } }
layer {        bottom: "res5b"        bottom: "res5c_branch2c"        top: "res5c"        name: "res5c"        type: "Eltwise"}
layer {        bottom: "res5c"        top: "res5c"        name: "res5c_relu"        type: "ReLU"}


########################################################################################################## Transition Up (Decoding)###########################################################################################################

#################################################
layer { bottom: 'res5c'          top: 'u6a'        name: 'upconv_d7c_u6a' type: 'Deconvolution'     convolution_param { bias_term: false num_output: 1024   pad: 0 kernel_size: 2 stride: 2 weight_filler { type: 'msra' }} }
layer { bottom: 'u6a'               top: 'normu6a'    name: 'bn_u6a'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu6a'           top: 'scaleu6a'   name: 'sc_u6a'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu6a'          top: 'scaleu6a'   name: 'relu_u6a'       type: 'ReLU' }
layer { bottom: 'scaleu6a' bottom: 'res4b22' top: 'u6b'   name: 'concat_d6c_u6a-b'  type: 'Concat' }
layer { bottom: 'u6b'               top: 'u6c'        name: 'conv_u6b-c'     type: 'Convolution'     convolution_param { bias_term: false num_output: 1024   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u6c'               top: 'normu6c'    name: 'bn_u6c'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu6c'           top: 'scaleu6c'   name: 'sc_u6c'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu6c'          top: 'scaleu6c'   name: 'relu_u6c'       type: 'ReLU' }
#layer { bottom: 'scaleu6c' bottom: 'u6b' top: 'u6d1'   name: 'concat1'  type: 'Concat' }
layer { bottom: 'scaleu6c'          top: 'u6d'        name: 'conv_u6c-d'     type: 'Convolution'     convolution_param { bias_term: false num_output: 1024   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u6d'               top: 'normu6d'    name: 'bn_u6d'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu6d'           top: 'scaleu6d'   name: 'sc_u6d'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu6d'          top: 'scaleu6d'   name: 'relu_u6d'       type: 'ReLU' }
#layer { bottom: 'scaleu6d' bottom: 'u6d1' top: 'x1'   name: 'concat1a'  type: 'Concat' }
#################################################

#################################################
layer { bottom: 'scaleu6d'          top: 'u5a'        name: 'upconv_d6c_u5a' type: 'Deconvolution'     convolution_param { bias_term: false num_output: 512   pad: 0 kernel_size: 2 stride: 2 weight_filler { type: 'msra' }} }
layer { bottom: 'u5a'               top: 'normu5a'    name: 'bn_u5a'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu5a'           top: 'scaleu5a'   name: 'sc_u5a'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu5a'          top: 'scaleu5a'   name: 'relu_u5a'       type: 'ReLU' }
layer { bottom: 'scaleu5a' bottom: 'res3b3' top: 'u5b'   name: 'concat_d5c_u5a-b'  type: 'Concat' }
layer { bottom: 'u5b'               top: 'u5c'        name: 'conv_u5b-c'     type: 'Convolution'     convolution_param { bias_term: false num_output: 512  pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u5c'               top: 'normu5c'    name: 'bn_u5c'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu5c'           top: 'scaleu5c'   name: 'sc_u5c'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu5c'          top: 'scaleu5c'   name: 'relu_u5c'       type: 'ReLU' }
#layer { bottom: 'scaleu5c' bottom: 'u5b' top: 'u5d1'   name: 'concat2'  type: 'Concat' }
layer { bottom: 'scaleu5c'          top: 'u5d'        name: 'conv_u5c-d'     type: 'Convolution'     convolution_param { bias_term: false num_output: 512   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u5d'               top: 'normu5d'    name: 'bn_u5d'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu5d'           top: 'scaleu5d'   name: 'sc_u5d'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu5d'          top: 'scaleu5d'   name: 'relu_u5d'       type: 'ReLU' }
#layer { bottom: 'scaleu5d' bottom: 'u5d1' top: 'x2'   name: 'concat2a'  type: 'Concat' }
#################################################


#################################################
layer { bottom: 'scaleu5d'          top: 'u4a'        name: 'upconv_d5c_u4a' type: 'Deconvolution'     convolution_param { bias_term: false num_output: 256   pad: 0 kernel_size: 2 stride: 2 weight_filler { type: 'msra' }} }
layer { bottom: 'u4a'               top: 'normu4a'    name: 'bn_u4a'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu4a'           top: 'scaleu4a'   name: 'sc_u4a'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu4a'          top: 'scaleu4a'   name: 'relu_u4a'       type: 'ReLU' }
layer { bottom: 'scaleu4a' bottom: 'res2c' top: 'u4b'   name: 'concat_d4c_u4a-b'  type: 'Concat' }
layer { bottom: 'u4b'               top: 'u4c'        name: 'conv_u4b-c'     type: 'Convolution'     convolution_param { bias_term: false num_output: 256   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u4c'               top: 'normu4c'    name: 'bn_u4c'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu4c'           top: 'scaleu4c'   name: 'sc_u4c'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu4c'          top: 'scaleu4c'   name: 'relu_u4c'       type: 'ReLU' }
#layer { bottom: 'scaleu4c' bottom: 'u4b' top: 'u4d1'   name: 'concat3'  type: 'Concat' }
layer { bottom: 'scaleu4c'          top: 'u4d'        name: 'conv_u4c-d'     type: 'Convolution'     convolution_param { bias_term: false num_output: 256   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u4d'               top: 'normu4d'    name: 'bn_u4d'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu4d'           top: 'scaleu4d'   name: 'sc_u4d'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu4d'          top: 'scaleu4d'   name: 'relu_u4d'       type: 'ReLU' }
#layer { bottom: 'scaleu4d' bottom: 'u4d1' top: 'x3'   name: 'concat3a'  type: 'Concat' }
#################################################


#################################################
layer { bottom: 'scaleu4d'          top: 'u3a'        name: 'upconv_d4c_u3a' type: 'Deconvolution'     convolution_param { bias_term: false num_output: 128   pad: 0 kernel_size: 2 stride: 2 weight_filler { type: 'msra' }} }
layer { bottom: 'u3a'               top: 'normu3a'    name: 'bn_u3a'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu3a'           top: 'scaleu3a'   name: 'sc_u3a'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu3a'          top: 'scaleu3a'   name: 'relu_u3a'       type: 'ReLU' }
layer { bottom: 'scaleu3a' bottom: 'conv1c' top: 'u3b'   name: 'concat_d3c_u3a-b'  type: 'Concat' }
layer { bottom: 'u3b'               top: 'u3c'        name: 'conv_u3b-c'     type: 'Convolution'     convolution_param { bias_term: false num_output: 128   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u3c'               top: 'normu3c'    name: 'bn_u3c'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu3c'           top: 'scaleu3c'   name: 'sc_u3c'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu3c'          top: 'scaleu3c'   name: 'relu_u3c'       type: 'ReLU' }
#layer { bottom: 'scaleu3c' bottom: 'u3b' top: 'u3d1'   name: 'concat4'  type: 'Concat' }
layer { bottom: 'scaleu3c'          top: 'u3d'        name: 'conv_u3c-d'     type: 'Convolution'     convolution_param { bias_term: false num_output: 128   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u3d'               top: 'normu3d'    name: 'bn_u3d'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu3d'           top: 'scaleu3d'   name: 'sc_u3d'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu3d'          top: 'scaleu3d'   name: 'relu_u3d'       type: 'ReLU' }
#layer { bottom: 'scaleu3d' bottom: 'u3d1' top: 'x4'   name: 'concat4a'  type: 'Concat' }


#################################################
layer { bottom: 'scaleu3d'          top: 'u2a'        name: 'upconv_d3c_u2a' type: 'Deconvolution'     convolution_param { bias_term: false num_output: 64   pad: 0 kernel_size: 2 stride: 2 weight_filler { type: 'msra' }} }
layer { bottom: 'u2a'               top: 'normu2a'    name: 'bn_u2a'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu2a'           top: 'scaleu2a'   name: 'sc_u2a'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu2a'          top: 'scaleu2a'   name: 'relu_u2a'       type: 'ReLU' }
layer { bottom: 'scaleu2a' bottom: 'conv0c' top: 'u2b'   name: 'concat_d2c_u2a-b'  type: 'Concat' }
layer { bottom: 'u2b'               top: 'u2c'        name: 'conv_u2b-c'     type: 'Convolution'     convolution_param { bias_term: false num_output: 64   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u2c'               top: 'normu2c'    name: 'bn_u2c'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu2c'           top: 'scaleu2c'   name: 'sc_u2c'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu2c'          top: 'scaleu2c'   name: 'relu_u2c'       type: 'ReLU' }
#layer { bottom: 'scaleu2c' bottom: 'u2b' top: 'u2d1'   name: 'concat5'  type: 'Concat' }
layer { bottom: 'scaleu2c'          top: 'u2d'        name: 'conv_u2c-d'     type: 'Convolution'     convolution_param { bias_term: false num_output: 64   pad: 1 kernel_size: 3         weight_filler { type: 'msra' }} }
layer { bottom: 'u2d'               top: 'normu2d'    name: 'bn_u2d'            type: 'BatchNorm'        param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }  param {    lr_mult: 0    decay_mult: 0  }}
layer { bottom: 'normu2d'           top: 'scaleu2d'   name: 'sc_u2d'            type: 'Scale'            scale_param {    bias_term: true  } }
layer { bottom: 'scaleu2d'          top: 'scaleu2d'   name: 'relu_u2d'       type: 'ReLU' }
#layer { bottom: 'scaleu2d' bottom: 'u2d1' top: 'x5'   name: 'concat5a'  type: 'Concat' }

################################################################################################### Flat Convolution ##########################################################################################################################

layer { bottom: 'scaleu2d'  top: 'score' name: 'conv_u0d-score' type: 'Convolution'   param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 }  convolution_param { num_output: 19 pad: 0 kernel_size: 1   weight_filler { type: 'msra' }} }

################################################################################################### Loss ######################################################################################################################################

layer { bottom: 'score' bottom: 'label' top: 'loss'  name: 'loss'   type: 'SoftmaxWithLoss' loss_param { ignore_label: 255 normalize: false } }
#layer { bottom: 'score' bottom: 'label' top: 'loss'  name: 'loss'   type: 'SoftmaxWithLoss' loss_param { normalize: false } }
